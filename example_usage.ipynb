{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataCleanser Example Usage\n",
    "\n",
    "This notebook demonstrates how to use the DataCleanser utility for EDA and data preprocessing, based on techniques from the kaggle-courses repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DataCleanser class\n",
    "from data_cleanser import DataCleanser\n",
    "\n",
    "# Other necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, let's create a sample dataset with common issues\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {\n",
    "    'age': np.random.normal(35, 10, n),  # Numeric feature\n",
    "    'income': np.random.exponential(50000, n),  # Skewed numeric feature\n",
    "    'gender': np.random.choice(['M', 'F', None], n, p=[0.48, 0.48, 0.04]),  # Categorical with missing values\n",
    "    'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD', None], n, p=[0.3, 0.4, 0.2, 0.05, 0.05]),  # Categorical\n",
    "    'signup_date': pd.date_range(start='2020-01-01', periods=n, freq='D')  # Date feature\n",
    "}\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add some outliers\n",
    "df.loc[np.random.choice(n, 20), 'age'] = np.random.uniform(70, 100, 20)\n",
    "df.loc[np.random.choice(n, 20), 'income'] = np.random.uniform(200000, 1000000, 20)\n",
    "\n",
    "# Add some missing values\n",
    "df.loc[np.random.choice(n, 50), 'age'] = np.nan\n",
    "df.loc[np.random.choice(n, 100), 'income'] = np.nan\n",
    "\n",
    "# Show the raw data\n",
    "print(\"Sample Dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize DataCleanser with our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataCleanser instance with our dataframe\n",
    "cleanser = DataCleanser(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic information about the dataset\n",
    "cleanser.get_basic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions of numeric features\n",
    "cleanser.visualize_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlations between numeric features\n",
    "cleanser.plot_correlations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Now let's clean the data with our DataCleanser utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values automatically\n",
    "cleanser.handle_missing_values(strategy='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers using IQR method\n",
    "cleanser.handle_outliers(method='iqr', threshold=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date features from signup_date\n",
    "cleanser.create_date_features('signup_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "cleanser.encode_categorical(method='onehot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "cleanser.scale_features(method='standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Get the Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the processed dataframe\n",
    "processed_df = cleanser.get_data()\n",
    "\n",
    "# View the cleaned and processed data\n",
    "print(\"Processed Dataset:\")\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any remaining issues\n",
    "print(\"Missing values:\", processed_df.isnull().sum().sum())\n",
    "\n",
    "# Summary statistics of processed data\n",
    "processed_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Reset to Original Data (if needed)\n",
    "\n",
    "If you want to try different preprocessing approaches, you can reset to the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset to original data\n",
    "cleanser.reset_to_original()\n",
    "\n",
    "# Verify we're back to original\n",
    "original_df = cleanser.get_data()\n",
    "print(\"Back to original data with missing values:\", original_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Alternative Preprocessing Pipeline\n",
    "\n",
    "Let's try a different approach using method chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complete pipeline using method chaining\n",
    "processed_df = cleanser.handle_missing_values(strategy='median') \\\n",
    "                     .handle_outliers(method='zscore', threshold=3) \\\n",
    "                     .create_date_features('signup_date', drop_original=True) \\\n",
    "                     .encode_categorical(method='label') \\\n",
    "                     .scale_features(method='minmax') \\\n",
    "                     .get_data()\n",
    "\n",
    "# Show results\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to use the DataCleanser utility for comprehensive data exploration and preprocessing. This follows best practices extracted from the kaggle-courses repository, making data preparation for machine learning models simpler and more standardized."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
